{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7249cfe4-ae5c-4002-b309-7345a8357aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plpi.models as P\n",
    "import transformers as T\n",
    "import copy\n",
    "\n",
    "ll_A = P.RobertaConfig(\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    classifier_dropout=None,\n",
    "    hidden_act=\"gelu\",\n",
    "    hidden_dropout_prob=0.1,\n",
    "    hidden_size=8192,\n",
    "    initializer_range=0.02,\n",
    "    intermediate_size=28672,\n",
    "    layer_norm_eps=1e-05,\n",
    "    max_position_embeddings=4096,\n",
    "    model_type=\"roberta\",\n",
    "    num_attention_heads=64,\n",
    "    num_hidden_layers=1,\n",
    "    position_embedding_type=\"absolute\",\n",
    "    bos_token_id=0,\n",
    "    pad_token_id=1,\n",
    "    eos_token_id=2,\n",
    "    type_vocab_size=1,\n",
    "    use_cache=True,\n",
    "    vocab_size=32000,\n",
    ")\n",
    "ll_B = copy.copy(ll_A)\n",
    "ll_B.plpi_head_configuration=\"pairwise\"\n",
    "ll_C = copy.copy(ll_A)\n",
    "ll_C.plpi_head_configuration=\"symmetric\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "087633fd-253a-4eb5-b724-8386fe52f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "lla = P.RobertaModel(ll_A)\n",
    "llb = P.RobertaModel(ll_B)\n",
    "llc = P.RobertaModel(ll_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20a3e81d-acd0-4a97-b214-3da0bcdecf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param(m, layers):\n",
    "    n_enc = sum(p.numel() for p in m.encoder.parameters())\n",
    "    n_emb = sum(p.numel() for p in m.embeddings.parameters())\n",
    "    n_pool = sum(p.numel() for p in m.pooler.parameters())\n",
    "    total = n_emb + layers * n_enc + n_pool\n",
    "    print(f\"{total=:_}, {n_enc=:_}, {n_pool=:_}, {n_enc=:_}, total_n_enc={n_enc * layers:_}\")\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbbde0cc-c250-428a-8075-16cc2e4ec49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total=59_426_832_384, n_enc=738_299_904, n_pool=67_117_056, n_enc=738_299_904, total_n_enc=59_063_992_320\n",
      "total=54_141_353_984, n_enc=672_231_424, n_pool=67_117_056, n_enc=672_231_424, total_n_enc=53_778_513_920\n",
      "total=54_057_467_904, n_enc=671_182_848, n_pool=67_117_056, n_enc=671_182_848, total_n_enc=53_694_627_840\n"
     ]
    }
   ],
   "source": [
    "nlla = param(lla, 80)\n",
    "nllb = param(llb, 80)\n",
    "nllc = param(llc, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c548165d-718f-4a33-85e3-03582f7b57c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.894094111977362\n",
      "9.035252704207133\n"
     ]
    }
   ],
   "source": [
    "print(100 * (nlla - nllb) / nlla)\n",
    "print(100 * (nlla - nllc) / nlla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40f2496-e027-4cc1-aa62-525bef2005b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
